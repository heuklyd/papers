\documentclass[leqno]{article}

\usepackage[utf8]{inputenc}
\usepackage[width=14cm]{geometry}
\usepackage{amsmath,amsfonts,amssymb,amsthm}
\usepackage{xcolor}
\usepackage[hidelinks,pdfusetitle]{hyperref}
\usepackage{enumerate}

\theoremstyle{plain}
\newtheorem*{lemma*}{Lemma}
\newtheorem*{theorem*}{Theorem}

\usepackage[export]{adjustbox}
\graphicspath{ {./images/} }

\title{A product expansion of the Chen series}
\author{H.\ J.\ Sussmann\footnote{Partially supported by NSF Grant MCS78-02442}}
\date{
	Department of Mathematics\\
	Rutgers University \\
	New Brunswick, NJ 08903 \\	
	U.S.A.
}

\newcommand{\dd}{\,\mathrm{d}}
\newcommand{\Br}{\operatorname{Br}(\underline{X})}
\newcommand{\Ser}{\operatorname{Ser}}

\begin{document}
	
\noindent
Theory and Applications of Nonlinear Control Systems \\
C.I.\ Byrnes and A.\ Lindquist (editors) \\
\copyright Elsevier Science Publishers B.V.\ (North-Holland), 1986

{\let\newpage\relax\maketitle}

\maketitle

\renewcommand*\abstractname{}

\begin{abstract}
	We present an expansion for the Chen series as a product of exponentials of the members of a P.\ Hall basis multiplied by coefficients that have simple expressions as iterated integrals. We then discuss the convergence properties of the expansion.
\end{abstract}

\bigskip

The idea of associating a formal power series in noncommutative indeterminates to a control system has proven to be fruitful for many problems. The series (known as the "Chen series" in the work of M.\ Fliess and his coworkers) has a number of interesting properties, such as the fact that it is an exponential of a Lie series. However, no simple expression is known for the Lie series. The purpose of this note is to present a formula which expresses the Chen series as a product of exponentials of the elements of a Philip Hall basis, multiplied by coefficients that have very simple explicit expressions as iterated integrals of the controls.

Let $\underline{X}=\left\{X_{i}: i \in I\right\}$ be an indexed family of indeterminates. For a real number $T \geq 0$, let $U_{T}(I)$ denote the product of a family $\left\{L_{i}: i \in I\right\}$ of copies of the space $L^1([0, T], \mathbb{R})$. Final1y, let $U(I)=\bigcup_{0 \leq T} U_{T}(I)$. The elements of $U(I)$ are therefore indexed families $u=\left\{u_{i}(\cdot): i \in I\right\}$ such that there is a $T \geq 0$ (called the duration of $u$) with the property that each $u_{i}(\cdot)$ is a Lebesgue integrable real-valued function on $[0, T]$. The set $U(I)$ is a semigroup with identity, with respect to the operation $\star: U(I) \times U(I) \rightarrow U(I)$ of concatenation. (The concatenation $u \star v$ of $u=\left\{u_{i}(\cdot): i \in I\right\}$, with duration $T$, and $v=\left\{v_{i}(\cdot): i \in I\right\}$, with duration $T^{\prime}$, is the element $w=\left\{w_{j}(\cdot): i \in I\right\}$ of $U_{T+T^{\prime}}(I)$ given by $w_{i}(t)=u_{i}(t)$ for $0 \leq t \leq T$ and $w_{i}(t)=v_{i}(t-T)$ for $\left.T<t<T+T^{\prime} .\right)$

Let $\mathcal{I}(I)$ be the set of all finite sequences $\sigma=\left(i_{1}, \ldots, i_{k}\right)$ of elements of $I$, of arbitrary length $k$. We use $|\sigma|$ to denote the length of $\sigma$. (The empty sequence $\emptyset$ is included.) Also, we use $\mathcal{I}_{k}(I)$ to denote the set of sequences of length $k$. For each $\sigma \in \mathcal{I}(I)$ we define the monomial
\begin{equation}
	X_{\sigma}=X_{i_{1}} X_{i_{2}} \ldots X_{i_{k}}
\end{equation}
if $\sigma=\left(i_{1}, \ldots, i_{k}\right)$. (If $\sigma=\emptyset$, we let $X_{\sigma}=1$.) 
The set of all formal linear combinations $\sum_{\sigma \in \mathcal{I}(I)} a_{\sigma} X_{\sigma}$ such that $a_{\sigma} \in R$ for all $\sigma$ and $a_{\sigma}=0$ for all but finitely many $\sigma'$s is the \emph{free associative algebra generated by $\underline{X}$}, and is denoted by $A(\underline{X})$. 
The algebra of all formal sums $\sum_{\sigma \in \mathcal{I}(I)} a_{\sigma} X_{\sigma}$, where the $a_\sigma$ are real numbers, is denoted by $\hat{A}(\underline{X})$. 
If $\left\{S_{j}: j \in J\right\}$ is an indexed family of elements of $\hat{A}(\underline{X})$, and each $S_{j}$ is given by $S_{j}=\sum_{\sigma \in \mathcal{I}(I)} S_{j,\sigma} X_{\sigma}$, then the sum $\sum_{j \in J} S_{j}$ will be said to be \emph{convergent} if, for each $\sigma$, the set $\left\{j: S_{j, \sigma} \neq 0\right\}$ is finite. 
In that case, the sum of the series is a well defined element of $\hat{A}(\underline{X})$. 
For a $u \in U(I)$, given by $u=\left\{u_{i}(\cdot): i \in I\right\}$, with duration $T$, and a multiindex $\sigma=\left(i_{1}, \ldots, i_{k}\right) \in \mathcal{I}(I)$, we define the \emph{iterated integral}
\begin{equation}
	\int_{0}^{t} u_{\sigma}=\int_{0}^{t} \int_{0}^{\tau_1} \int_{0}^{\tau_2} \ldots \int_{0}^{\tau_{k-1}} u_{i_{1}}\left(\tau_{1}\right) u_{i_{2}}\left(\tau_{2}\right) \ldots u_{i_{k}}\left(\tau_{k}\right) \dd \tau_{k} \ldots \dd \tau_1,
\end{equation}
for $0 \leq t \leq T$. 
We then associate with $u$ the $\hat{A}(\underline{X})$-valued function $S_{u}$ on $[0,T]$ given by
\begin{equation}
	S_{u}(t)=\sum_{\sigma}\left(\int_{0}^{t} u_{\sigma}\right) X_{\sigma^*}
\end{equation}
(Here, for $\sigma=\left(i, \ldots, i_{k}\right)$, we use $\sigma^{*}$ to denote the reversed sequence $\left(i_{k}, \ldots, i_{1}\right)$. 
Also, we let $\int_{0}^{t} u_{\sigma}=1$ if $\sigma=\emptyset$.)
The series $S_{u}(T)$ is the \emph{formal power series} associated with $u$, and will be denoted by $\Ser(u)$. The map $\Ser: U(I) \rightarrow \hat{A}(\underline{X})$ is a semigroup homomorphism from $U(I)$ into $\hat{A}(X)$, with respect to the operations of concatenation and multiplication, respectively.

It is easy to see that the series-valued function $S_{u}$ is the solution of the differential equation
\begin{equation}
	\dot{S}(t)=S(t)\left(\sum_{i \in I} u_{i}(t) X_{i}\right)
\end{equation}
with initial condition $S(0)=1$. From this it follows easily that, if $u^{\star}$ denotes the element $\left\{u_{i}^{\star}(\cdot): i \in I\right\}$ of $U_{T}(I)$ given by $u_{i}^{\star}(t)=-u_{i}(T-t)$, then $\Ser(u) \Ser\left(u^{\star}\right)=1$. In particular, the image of $U(I)$ under $\Ser$ is a group under multiplication. This group will be denoted by $G_{0}(\underline{X})$. An important property of $G_{0}(\underline{X})$ is the inclusion $G_{0}(\underline{X}) \subseteq G(\underline{X})$, where $G(\underline{X})$ is the set of \emph{exponential Lie series} in the indeterminates $\underline{X}$. Precisely, let $L(\underline{X})$ denote the Lie subalgebra of $A(\underline{X})$ generated by the $X_{i}$. Then let $\hat{L}(\underline{X})$ denote the set of all elements of $\hat{A}(\underline{X})$ that are equal to a convergent sum $\sum_{j \in J} S_{j}$ of elements of $L(\underline{X})$. The elements of $\hat{L}(\underline{X})$ are the \emph{Lie series} in the indeterminates $\underline{X}$. If $S$ is any series in $\hat{A}(\underline{X})$ whose constant term (i.e.\ the coefficient of 1) vanishes (in particular if $S \in \hat{L}(\underline{X}))$, then the exponential $\exp(S)$ is well-defined by the series
\begin{equation}
	\exp (S)=\sum_{n=0}^{\infty} \frac{1}{n !} S^{n}.
\end{equation}
The series of the form $\exp (S)$, $S \in \hat{L}(\underline{X})$, are the \emph{exponential Lie series}. 
The Campbell-Hausdorff formula implies that the exponential Lie series form group under multiplication, which will be denoted by $G(\underline{X})$. 
There is a well defined \emph{logarithm} map which assigns, to every series $S \in \hat{A}(\underline{X})$ whose constant term is equal to one, the series $\log S$ given by
\begin{equation}
	\log S=\sum_{n=1}^{\infty} \frac{(-1)^{n+1}}{n}(S-1)^{n}
\end{equation}
The maps $\exp$ and $\log$ are inverses of each other. In particular, $\exp$ maps $\hat{L}(\underline{X})$ onto $G(\underline{X})$, and $\log$ maps $G(\underline{X})$ onto $\hat{L}(\underline{X})$.

Since our goal is to get an expression for $\Ser(u)$ that exhibits its significant properties, it is natural to write
\begin{equation}
	\Ser(u)=\exp (Z(u))
\end{equation}
and seek an expression for $Z(u)$. Moreover, an explicit expression for $Z(u)$ can easily be derived, since $Z(u)=\log S(u)$, and there is an explicit formula for the logarithm. The resulting formula is
\begin{equation} \label{eq:8}
	Z(u)=\sum_{n=1}^{\infty} \sum_{\sigma_{1} \in \mathcal{I}'(I)} \cdots \sum_{\sigma_{n} \in \mathcal{I}'(I)} \frac{(-1)^{n+1}}{n}\left(\int_{0}^{T} u_{\sigma_{1}}\right) \cdots\left(\int_{0}^{T} u_{\sigma_{n}}\right) X_{\sigma_{1}^{*}} \cdots X_{\sigma_{n}^{*}} \cdot
\end{equation}
(Here $\mathcal{I}'(I)=\mathcal{I}(I)-\{\emptyset\}.$) 
However, this expression is not very useful. 
(For instance, the fact that $Z(u)$ is a Lie series is not at all evident from \eqref{eq:8}.)

A slight simplification can be achieved by using the fact that $Z(u) \in \hat{L}(\underline{X})$. For each monomial $X_{\sigma}=X_{i_{1}} \cdots X_{i_{k}}$, define $\left[X_{\sigma}\right]$ by
\begin{equation}
	\left[X_{\sigma}\right]=\left[X_{i_{1}},\left[X_{i_{2}},\left[\ldots\left[X_{i_{k-1}}, X_{i_{k}}\right] \cdots\right]\right]\right].
\end{equation}
Then it can be proved that, if $A=\sum_{\sigma} a_{\sigma} X_{\sigma}$ happens to be a Lie series, then $A=\sum_{\sigma} \frac{a_{\sigma}}{|\sigma|}\left[X_{\sigma}\right]$. In particular, this yields the formula
\begin{equation} \label{eq:10}
	Z(u)=\sum_{n=1}^{\infty} \sum_{\sigma_{1} \in \mathcal{I}'(I)} \cdots \sum_{\sigma_{n} \in \mathcal{I}'(I)} \frac{(-1)^{n+1}}{n(|\sigma_1|+ \dotsb +|\sigma_n|)}\left(\int_{0}^{T} u_{\sigma_{1}}\right) \cdots\left(\int_{0}^{T} u_{\sigma_{n}}\right) [X_{\sigma_{1}^{*}} \cdots X_{\sigma_{n}^{*}}].
\end{equation}
This formula is clearly better than \eqref{eq:8}, but it is still far from solving our problem, since the Lie monomials that occur in \eqref{eq:10} are not linearly independent, and there is no easy way to single out a basis and write down the corresponding coefficients.

As an alternative to the above formulas for $\Ser(u)$ and $Z(u)$, we propose to the write an expression for $\Ser(u)$ as an infinite product of exponentials. First, we have to give a precise definition of the infinite products. For any series $S \in \hat{A}(\underline{X})$, let us use $\langle S, \sigma\rangle$ to denote the coefficient of $X_{\sigma}$, so that $S=\sum\langle S, \sigma\rangle X_\sigma$. Let $J$ be a set which is totally ordered by a relation $\leq$. Let $\left\{S^{j}:j \in J\right\}$ be a family of series in $\hat{A}(\underline{X})$, indexed by $j \in J$. We define the infinite product $\overleftarrow{\prod}_{j \in J} S^{j}$ by:
\begin{equation}
	\overleftarrow{\prod_{j \in J}} S^{j} = \sum_{\sigma \in \mathcal{I}(I)} P_{\sigma} X_{\sigma}
\end{equation}
where
\begin{equation} \label{eq:12}
	P_{\sigma} = 
	\sum_{n=0}^{\infty} 
	\sum_{\substack{j_{1} \in J, \ldots, j_{n} \in J \\ j_1 > j_2 > \dotsb > j_n}}
	\sum_{\substack{\sigma_{1} \in \mathcal{I}'(I), \ldots, \sigma_{n} \in \mathcal{I}'(I) \\ \sigma_1 \# \sigma_2 \# \dotsb \# \sigma_n = \sigma}} 
	\langle S^{j_1}, \sigma_{1}\rangle \cdots \langle S^{j_{n}}, \sigma_{n} \rangle.
\end{equation}
Here, if $\sigma_{1}, \ldots, \sigma_{n}$ are in $\mathcal{I}(I)$, we use $\sigma_{1} \# \ldots \# \sigma_{n}$ to denote the concatenation of $\sigma_{1}, \sigma_{2}, \ldots$, $\sigma_{n}$ (so that $X_{\sigma_{1} \# \sigma_{2} \# \cdots \# \sigma_{n}} =X_{\sigma_{1}} X_{\sigma_{2}} \cdots X_{\sigma_{n}}$ ). If $\sigma=\emptyset$, then \eqref{eq:12} implies that $P_{\sigma}=1$. The product is defined provided that: (i) all the $S^j_\emptyset$ are equal to $1$, and (ii) for each $\sigma$ there are only finitely many choices of $n$, $j_{1}, \ldots, j_{n}$, $\sigma_{1}, \ldots, \sigma_{n}$, such that $j_{1} \in J, \ldots, j_{n} \in J$, $j_{1}>j_{2}>\cdots>j_{n}$, $\sigma_{1} \in \mathcal{I}'(I), \ldots, \sigma_{n} \in \mathcal{I}'(I)$, $\sigma_{1} \# \cdots \# \sigma_{n}=\sigma$, and $\langle S^{j_{1}}, \sigma_{1}\rangle\langle S^{j_{2}}, \sigma_{2}\rangle\cdots\langle S^{j_n}, \sigma_{n}\rangle>\neq 0$.

Next we have to define the concept of a \emph{P.\ Hall basis} of $L(\underline{X})$. First, we define the set $\Br$ of \emph{formal brackets} in the indeterminates $\underline{X}$. (This is essentially the same as the \emph{magma} generated by $\underline{X}$.)
Let $A$ be the alphabet that consists of the $X_{i}$, the left and right square brackets, and the comma. Then $\Br$ is the smallest set $\Omega$ of words in the alphabet $A$, such that (i) $X_{i} \in \Omega$ for all $i \in I$, and (ii) whenever $\alpha, \beta$ are two words that belong to $\Omega$, then the word ``$[\alpha,\beta]$'' also belongs to $\Omega$.
Every formal bracket $B \in \Br$ has a well-defined \emph{degree} $\operatorname{deg}(B)$, which is an integer $\geq 1$. 
If $\operatorname{deg}(B) \geq 2$, then $B$ can be written in a unique way as $\left[B_{1}, B_{2}\right]$, with $B_{1} \in \Br, B_{2} \in \Br$
The formal brackets $B_{1},_{2} B_{2}$ are called the \emph{left and right factors} of $B$, and are denoted by $\lambda(B)$ and $\rho(B)$, respectively. 
There is a mapping $\mu$ which associates with each $B \in \Br$ an element of $L(\underline{X})$. 
The elements of $L(\underline{X})$ of the form $\mu(B)$, $B \in \Br$, are the \emph{Lie monomials} in the $X_{i}$. (But notice that: (a) the map $\mu$ is not one-to-one, and (b) the unique factorization is a property of the \emph{formal brackets}, not of the Lie monomials. 
For instance, if $X$ and $Y$ are two different indeterminates, and we let $B_{1}=[X,[Y,[X, Y]]]$, $B_{2}=[Y,[X,[X, Y]]]$, then $\lambda\left(B_{1}\right)=X$ and $\lambda\left(B_{2}\right)=Y$. 
However, the Jacobi identity implies that $\mu\left(B_1\right)=\mu\left(B_{2}\right)$.)

A \emph{Philip Hall basis} of $L(\underline{X})$ is a subset $\mathcal{B}$ of $\Br$, totally ordered by a relation $\leq$, such that:
\begin{enumerate}[(I)]
	\item every $X_{i}$ is in $\mathcal{B}$,
	\item if $B_{1} \in \mathcal{B}, B_{2} \in \mathcal{B}$, and $B_{1} \leq B_{2}$, then $\operatorname{deg}\left(B_{1}\right) \leq \operatorname{deg}\left(B_{2}\right)$,
	\item if $B \in \Br$ and $\operatorname{deg}(B) \geq 2$, so that $B=\left[B_{1}, B_{2}\right], B_{1} \in \Br$, $B_{2} \in \Br$, then $B \in \mathcal{B}$ if and only if: (a) $B_{1} \in \mathcal{B}$ and $B_{2} \in \mathcal{B}$, (b) $B_{1} < B_{2}$, and (c)	 either $\operatorname{deg}\left(B_{2}\right)=1$ or $\lambda\left(B_{2}\right) \leq B_{1}$.
\end{enumerate}
If $(\mathcal{B}, \leq)$ is a P.\ Hall basis of $L(\underline{X})$, then it can be proved that $\mu$ is one to one on $\mathcal{B}$, so that $\mathcal{B}$ can also be regarded as a set of Lie monomials.
When this is done, then $B$ turns out to be a basis of $L(X)$ (cf.\ \cite{1,2,3}). 

We then have

\begin{lemma*}
	Let $\mathcal{B}$ be a P.\ Hall basis of $L(\underline{X})$. Then:
	\begin{enumerate}[(i)]
		\item for every familly $\alpha=\left\{\alpha_{B}: B \in \mathcal{B}\right\}$ of real numbers, the infinite product
		\begin{equation}
			\overleftarrow{P}_{\mathcal{B}}(\alpha) = \overleftarrow{\prod_{B\in\mathcal{B}}} \exp (\alpha_B B)
		\end{equation}
		is defined,
		\item $\alpha \rightarrow \overleftarrow{P}_{\mathcal{B}}(\alpha)$ is a bijection from $\mathbb{R}^{\mathcal{B}}$ onto $G(\underline{X})$.
	\end{enumerate}
\end{lemma*}

\begin{proof}
	Let $S^{B}=\exp \left(\alpha_{B} B\right)$. 
	It is clear that $\left\langle S^{B}, \emptyset\right\rangle=1$ for all B. Let $\sigma=\left(i_{1}, \ldots, i_{k}\right) \in \mathcal{I}(I)$. Then $\sigma \in \mathcal{I}(F)$ for some finite subset of $I$. 
	If $B \in \Br$, let $\operatorname{supp}(B)$ denote the set of those $i \in I$ that occur in $B$. (That is: $\operatorname{supp}\left(X_{i}\right)=\{i\}$, and $\operatorname{supp}\left[B_{1}, B_{2}\right]=\operatorname{supp}\left(B_{1}\right) \cup \operatorname{supp}\left(B_{2}\right)$.) 
	Then it is easy to show that, if $B=\sum_{\tau \in \mathcal{I}(I)} B_{\tau} X_{\tau}$, then al1 the $X_{\tau}$ for which $B_{\tau} \neq 0$ are such that $\operatorname{supp}(\tau)=\operatorname{supp}(B)$. (If $\tau=\left(\tau_{1}, \ldots, \tau_{m}\right)$, we define $\operatorname{supp}(\tau)=\left\{\tau_1, \ldots, \tau_{m}\right\}$.) 
	If $\alpha \in \mathbb{R}, B \in \Br$, and $\alpha \neq 0$, the series $\exp (\alpha B)$ also has the property that the only monomials $X_{\tau}$ of positive degree that can occur are those for which $\operatorname{supp}(\tau)=\operatorname{supp}(B)$. 
	If $\sigma_{1}, \ldots, \sigma_{n}$, $B_{1}, \ldots, B_{n}$ are such that $\sigma_{i} \in \mathcal{I}'(I)$, $B_{i} \in \mathcal{B}$, $\sigma_1\#\dotsb\#\sigma_{n}=\sigma$, $B_{1}>B_{2}>\cdots>B_{n}$, and $\langle B_{i}, \sigma_{i}\rangle\neq 0$ for $i=1, \ldots, n$, then $\operatorname{supp}(B_{i})=\operatorname{supp}\left(\sigma_{i}\right)$, and so $\operatorname{supp}\left(B_{i}\right) \subseteq F$.
	Moreover, $1 \leq \operatorname{deg}\left(B_{i}\right) \leq\left|\sigma_{i}\right| \leq|\sigma|$. Hence $n \leq|\sigma|$. 
	Since there are only finitely many elements $B$ of $\Br$ such that $\operatorname{supp}(B) \subseteq F$ and $\operatorname{deg}(B) \leq|\sigma|$, we conclude that the number of choices of $n$, $\sigma_1, \ldots, \sigma_{n}$, $B_{1}, \ldots, B_{n}$ is finite. 
	So $\overleftarrow{P}_\mathcal{B}(\alpha)$ is defined.

	That $\overleftarrow{P}_\mathcal{B}(\alpha)$ is an exponential Lie series follows easily from the Friedrichs criterion (cf.\ Serre~\cite{2}). 
	If $S$ is an exponential Lie series, let $S=\exp (Z)$, $\Sigma \in \hat{L}(\underline{X})$. 
	Write $Z=\tilde{Z}_{2}+\sum_{B \in \mathcal{B}_{1}} \alpha_{B} B$, where $\mathcal{B}_{1}$ is the set of those $B \in \mathcal{B}$ such that: $\operatorname{deg}(B)=1$, and $\tilde{Z}_{2} \in \hat{L}(\underline{X})$ contains no monomial of degree one. Then the Campbell-Hausdorff formula implies that
	\begin{equation}
		\exp(Z) \cdot \left( \overleftarrow{\prod_{B \in \mathcal{B}_1}} \exp (\alpha_B B) \right)^{-1} = \exp(Z_2),
	\end{equation}
	where $Z_{2}$ contains no monomials of degree one. Suppose that we have defined the $\alpha_B$ for $B \in \mathcal{B}_{k}$ (where $\mathcal{B}_{k}=\{B: B \in \mathcal{B}$, $\operatorname{deg}(B) \leq k\}$ ) such that
	\begin{equation} \label{eq:15}
		\exp (Z) \cdot\left(\overleftarrow{\prod_{B \in \mathcal{B}_{k}}} \exp \left(\alpha_{B} B\right)\right)^{-1}=\exp \left(Z_{k+1}\right)
	\end{equation}
	where $Z_{k+1}$ contains no monomial of degree $\leq k$. Then we let
	\begin{equation*}
		Z_{k+1}=\tilde{Z}_{k+2}+\sum_{\substack{B \in \mathcal{B} \\ \operatorname{deg}(B)=k+1}} \alpha_{B} B,
	\end{equation*}
	where $\tilde{Z}_{k+2}$ contains no monomials of degree $\leq k+1$. Then \eqref{eq:15} holds, with a suitable choice of $Z_{k+2}$, if $k$ is replaced by $k+1$. So the $\alpha_{B}$ are defined for all $B \in \mathcal{B}$, and \eqref{eq:15} holds for all $k$. 
	From this it follows easily that $S=\overleftarrow{P}_{\mathcal{B}}(\alpha)$.

	Finally, we must show that the map $\alpha \rightarrow \overleftarrow{P}_{\mathcal{B}}(\alpha)$ is injective. 
	Let $\alpha$, $\beta$ be such that $\overleftarrow{P}_{\mathcal{B}}(\alpha) = \overleftarrow{P}_{\mathcal{B}}(\beta)$. 
	Suppose that $\alpha \neq \beta$. 
	Let $B^{*}$ be the first element $B$ of $\mathcal{B}$ such that $\alpha_{B} \neq \beta_{B}$. 
	Then
	\begin{equation} \label{eq:16}
		\underset{\substack{B \in \mathcal{B}\\B \geq B^*}}{\stackrel{\leftarrow}{\Pi}} \exp \left(\alpha_{B} B\right)=\underset{\substack{B \in \mathcal{B}\\B \geq B^*}}{\stackrel{\leftarrow}{\Pi}} \exp \left(\beta_{B} B\right).
	\end{equation}
	The left side is equal to $1+\Sigma^{\#} \alpha_{B} B+S_{1}$, where the sum $\Sigma^{\#}$ runs over those $B \in \mathcal{B}$ such that $B \geq B^{*}$ and $\operatorname{deg}(B)=\operatorname{deg}\left(B^{*}\right)$, and $S_{1}$ contains no monomials of degree $\leq 1+\operatorname{deg}\left(B^{*}\right)$.

	A similar expression holds for the right side of \eqref{eq:16}. So $\Sigma^{\#} \alpha_{B} B=\Sigma^{\#} \beta_{B} B$. 
	Since $\mathcal{B}$ is a linearly independent set, we have $\alpha_{B^*} = \beta_{B^*}$, which is a contradiction. 
	Hence $\alpha=\beta$, and our proof is complete.
\end{proof}

The lemma implies, in particular, that
\begin{equation} \label{eq:17}
	\Ser(u) = \overleftarrow{\prod_{B \in \mathcal{B}}} \exp(\alpha_B(u)B),
\end{equation}
where the $\alpha_{B}$ are real-valued functions on $U(I)$, uniquely determined by \eqref{eq:17}. 
Our goal is to exhibit an explicit formula for the $\alpha_{B}(\cdot)$ as iterated integrals. 
We shall associate with each formal bracket $B \in \Br$, and each $u \in U(I)$, two functions $C_B(u)$, $c_B(u)$ defined on the interval $[0,T]$ (if $T$ is the duration of $u$). 
The function $c_B(u)$ will be in $L^1([0,T],\mathbb{R})$, and then $C_B(u)$ will be given by
\begin{equation}
	\label{eq:18}
	C_{B}(u)(t)=\int_{0}^{t} C_{B}(u)(s) \dd s.
\end{equation}

The $c_{B}(u), C_{B}(u)$ are defined as follows. Let $u=\left\{u_{i}(\cdot): i \in I\right\}$. 
For $B=X_{i}$, we let $c_{B}(u)(t)=u_{i}(t)$, $0 \leq t \leq T$, and then define $C_{B}(u)$ by \eqref{eq:18}. 
Assume that $c_{B}(u)$ and $C_{B}(u)$ have been defined for all $B \in \Br$ such that $\operatorname{deg}(B)<k$, and let $B \in \Br$ have degree $k+1$. 
Then $B$ can be written in a unique way as $(\operatorname{ad} B_1)^m (B_2)$, with $\lambda\left(B_{2}\right) \neq B_1$, $m \geq 1$.
(As usual, $\operatorname{ad} P$ is the mapping $Q \to [P, Q]$.)
We then define
\begin{equation} \label{eq:19}
	c_{B}(u)=\frac{1}{m !} C_{B_{1}}(u)^{m} c_{B_{2}}(u)
\end{equation}
and, again, we define $C_{B}(u)$ by \eqref{eq:18}. 
This completes the recursive definition of the $c_{B}(u)$, $C_{B}(u)$. We then have:

\begin{theorem*}
	Let $u \in U(I)$ have duration $T$. 
	Let $\mathcal{B}$ be a P.\ Hall basis of $L(X)$.
	Then
	\begin{equation} \label{eq:20}
		\Ser(u) = \overleftarrow{\prod_{B \in \mathcal{B}}} \exp \left(C_B(u)(T) B\right).
	\end{equation}
\end{theorem*}

Formula \eqref{eq:20} is the desired product expansion.

\begin{proof}
	Let $\sigma \in \mathcal{I}(I)$ and let $F \subseteq I$ be finite and such that $\sigma \in \mathcal{I}(F)$. Let $u^{F}=\left\{u_{i}(\cdot): i \in F\right\}$, Let $\underline{X}^{F}=\left\{X_{i}: i \in F\right\}$, and let $\pi^{F}: \hat{A}(\underline{X}) \rightarrow \hat{A}\left(\underline{X}^{F}\right)$ be the map that sends $X_{i}$ to $X_i$ if $i \in F$, and to zero if $i \notin F$.
	Then, if $Q$ is any series in $\hat{A}(X)$ the coefficients $\langle Q, \sigma \rangle$ and $\langle \pi^F (Q),\sigma \rangle$ are equal.
	To prove that $X_\sigma$ has the same coefficient in both sides of \eqref{eq:20}, it suffices to show that the results of applying $F$ to both sides of \eqref{eq:20} are the same.
	But $\pi^{F}(\Ser(u))=\Ser\left(u^{F}\right)$, and $\pi^{F}\left(\overleftarrow{\prod}_{B \in \mathcal{B}} \exp \left(C_{B}(u)(T) B\right)\right) = \overleftarrow{\prod}_{B \in \mathcal{B}^{F}} \exp \left(C_{B}\left(u^{F}\right)(T) {B}\right)$ where $\mathcal{B}^F$ is the set of those $B \in \mathcal{B}$ that only contain $X_i$'s that belong to $F$.	
	Hence it suffices to prove \eqref{eq:20} when $I$ is a finite set.  From now on, we assume that $I$ is finite.

	Let $\mathcal{B}(k)=\{B: B \in \mathcal{B}, \operatorname{deg}(B)=k\}$. 
	Then each $\mathcal{B}(k)$ is a finite set. 
	Since the total order $\leq$ is such that $B_{1} \leq B_{2}$ implies $\operatorname{deg}\left(B_1\right) \leq \operatorname{deg}\left(B_{2}\right)$, the elements of $\mathcal{B}$ can be arranged in a sequence $B_1, B_2, B_3, \ldots$ in such a way that $B_{1}<B_{2}<B_{3}<\ldots$. 
	We will construct, by induction on $j$ (for $j=0,1,2, \ldots$), a finite subset $F_{j}$ of $\mathcal{B}$, such that:
	
	(a) $\operatorname{card}\left(F_{j}\right)=j$,

	(b) if we define, for a $u \in U(I)$ of duration $t$, the $\hat{A}(\underline{X})$-valued function $S_{u}^{j}$, by
	\begin{equation} \label{eq:21}
		S_{u}(t)=S_{u}^{j}(t) \cdot \overleftarrow{\prod_{B \in F_j}} \exp \left\{\left(\int_{0}^{t} c_{B}(u)(s) \dd s\right) \cdot B\right\}, \quad 0 \leq t \leq T
	\end{equation}
	then $S_{u}^{j}$ satisfies the differential equation
	\begin{equation}
		\dot{S}_{u}^{j}(t)=S_{u}^{j}(t) \cdot\left(\sum_{B \in G_{j}} c_{B}(u)(t) B\right),
	\end{equation}
	together with the initial condition $S_{u}^{j}(0)=1$, where $G_{j}$ is a subset of $B$ such that: (i) $B_{1} < B_{2}$ for all $B_{1} \in F_{j}$, $B_{2} \in G_{j}$, and (ii) if $B_{j}^{*}$ is the $\leq$-first element of $G_{j}$, then every $B \in G_{j}$ such that $B \neq B_{j}^{*}$ and $\operatorname{deg}(B)>1$ satisfies $\lambda(B) \leq B_{j}^{*}$

	For $j=0$, we let $F_{j}=\emptyset$, $G_{j}=\mathcal{B}(1)$, $S_{u}^{j}(t)=S_{u}(t)$. 
	Then all the conditions are satisfied. 
	Now assume $F_{j}$ has been constructed for a particular $j$, in such a way that (a) and (b) hold, and let $G_{j}$, $B_{j}^{*}$, S$_{u}^{j}$ be as specified in (b). 
	We define $F_{j+1}=F_{j} \cup\left\{B_{j}^{*}\right\}$.
	Since $B_{j}^{*} \in G_{j}$, we have $B_{j}^{*}>B$ for every $B \in F_{j}$.
	In particular, $B_{j}^{*} \notin F_{j}$, and so $\operatorname{card} \left(F_{j+1}\right)=j+1$. 
	The series $S_{u}^{j+1}(t)$ then satisfies:
	\begin{equation}
		S_{u}^{j}(t)=S_{u}^{j+1}(t) \cdot \exp \left\{\left(\int_{0}^{t} c_{B_{j}^*}(u)(s) \dd s\right) B_{j}^{*}\right\}.
	\end{equation}
	Then
	\begin{equation}
		\dot{S}_{u}^{j}(t) = S_{u}^{j}(t) \cdot c_{B_j^*}(u)(t) B_{j}^{*}+\dot{S}_{u}^{j+1}(t) \exp \left\{\left(\int_{0}^{t} c_{B_{j}^*}(u)(s) \dd s\right) B_{j}^{*}\right\},
	\end{equation}
	so that
	\begin{equation}
		S_{u}^{j}(t)\left(\sum_{\substack{B \in G_{j}\\B \neq B_{j}^{*}}} c_{B}(u)(t) B\right)=\dot{S}_{u}^{j+1}(t) \exp \left(C_{B_{j}^{*}}(u)(t) B_{j}^{*}\right)
	\end{equation}
	and then
	\begin{equation}
		\dot{S}_{u}^{j+1}(t)=S_{u}^{j+1}(t) \cdot D_{u}^{j}(t)
	\end{equation}
	where
	\begin{equation}
		D_{u}^{j}(t)=\exp \left(C_{B_{j}^{*}}(u)(t) B_{j}^{*}\right) \cdot\left(\sum_{\substack{B \in G_{j}\\B \neq B_{j}^{*}}} c_{B}(u)(t) B\right) \cdot \exp \left(-C_{B_{j}^{*}}(u)(t) B_{j}^{*}\right).
	\end{equation}
	Then
	\begin{equation} \label{eq:28}
		D^j_u(t) = \sum_{m=0}^\infty \sum_{\substack{B \in G_{j}\\B \neq B_{j}^{*}}} \frac{1}{m!} \left\{ C_{B_j^*}(u)(t)\right\}^m c_B(u)(t) E_{m,B},
	\end{equation}
	where
	\begin{equation}
		E_{m, B}=\left(\operatorname{ad} B_{j}^{*}\right)^{m}(B).
	\end{equation}
	The brackets $E_{m, B}$, for $B \in G_{j}$, $B \neq B_{j}^{*}$, and $m=\{0,1, \ldots\}$, are in $\mathcal{B}$. 
	This is clear for $m=0$, because $G_{j} \subseteq \mathcal{B}$. 
	For $m=1$, $E_{m, B}$ is the bracket $\left[B_{j}^{*}, B\right]$.
	Both $B_{j}^{*}$ and $B$ are in $\mathcal{B}$. 
	Moreover, $B_{j}^{*}<B$, because $B_{j}^{*}$ was the $\leq$-first element of $G_{j}$. 
	Finally, the inductive assumption (item (ii) of (b)) tells us that, if $\operatorname{deg}(B)>1$, then the left factor of $B$ satisfies $\lambda(B) \leq B_{j}^{*}$. 
	Hence the definition of the P.\ Hall basis shows that $E_{m, B} \in \mathcal{B}$. 
	Assume that $E_{m, B} \in \mathcal{B}$ for some $m \geq 1$. 
	Then $E_{m+1, B}=\left[B_{j}^{*}, E_{m, B}\right]$, and both $B_{j}^{*}$ and $E_{m, B}$ are in $\mathcal{B}$. 
	Moreover, $\operatorname{deg}\left(B_{j}^{*}\right)<\operatorname{deg}\left(E_{m, B}\right)$, and so $B_{j}^{*} < E_{m, B}$. 
	Finally, the left factor of $E_{m, B}$ is $B_{j}^{*}$, and so $\lambda\left(E_{m, B}\right) \leq B_{j}^{*}$. 
	So $E_{m+1, B} \in \mathcal{B}$. 
	This establishes that $E_{m, B} \in \mathcal{B}$ for all $m$ and all $B \in G_{j}-\left\{B_{j}^{*}\right\}$.

	Next we show that the $E_{m, B}$ are all different, i.e.\ that $E_{m, B}$ cannot be equal to $E_{m',B'}$ unless $m=m'$ and $B=B'$. 
	To see this, notice that each $B'\in\Br$ can be written in a unique way as $\left(\operatorname{ad} B_{1}\right)^{m}\left(B_{2}\right)$, for some $m, B_{1}, B_{2}$ such that $B_{1} \neq B_{2}$. (We let $B_{1}=\lambda\left(B'\right)$; then we define $H^{i}, K^{i}$ by $H^{1}=B_{1}$, $K^{1}=B_{2}, H^{i+1}=\lambda\left(K^{i}\right), K^{i+1}=\rho\left(K^{i}\right)$. The integer $m$ is then the first $i$ such that $H^{i} \neq H^{i+1}$, and $B_{2}$ can then be recovered, since $B_{2}=K^{m}$.) If we apply this when $B'=E_{m, B}$, we see that $m$ and $B$ can be recovered from $E_{m, B}$. Since the $E_{m, B}$ are all different, and the coefficient of $E_{m, B}$ in \eqref{eq:28} is obviously $c_{E_{m, B}}(u)(t)$, we can rewrite \eqref{eq:28} as
	\begin{equation}
		D_{u}^{j}(t)=\sum_{B \in G_{j+1}} c_{B}(u)(t) B
	\end{equation}
	where $G_{j+1}$ is the set whose elements are the $E_{m, B}$.
	We must now show that $F_{j+1}, G_{j+1}$ satisfy conditions (i), (ii) of (b). 
	Let $B_{1} \in F_{j+1}, B_{2} \in G_{j+1}$. 
	Then $B_{2}=E_{m, B}$ for some $m$ and some $B \in G_{j}, B \neq B_{j}^{*}$. 
	If $m=0$, then $B>B_j^*$ because $B_{j}^{*}$ is the $\leq$-first element of $G_{j}$. 
	So $B_{2}>B_{j}^{*}$. 
	If $m>0$, then $\lambda\left(B_{2}\right)=B_{j}^{*}$, and so $\operatorname{deg}\left(B_{2}\right)>\operatorname{deg}\left(B_{j}^{*}\right)$, and therefore $B_{2}>B_{j}^{*}$. 
	In either case we have shown that $B_{2}>B_{j}^{*}$.
	If $B_{1}=B_{j}^{*}$, then $B_{2}>B_{1}$. 
	If $B_{1} \in F_{j}$, then $B_{2}>B_1$ as well, because $B_{j}^{*} \in G_{j}$ and so $B_{1}<B_{j}^{*}$. 
	So (i) holds. 
	We now prove (ii). 
	Let $B_{j+1}^{*}$ be the $\leq$-first element of $G_{j+1}$. 
	Let $B \in G_{j+1}, B \neq B_{j+1}^{*}$. 
	Then $B=E_{m, B'}$ for some $m$ and some $B' \in G_{j}$.
	Assume that $\operatorname{deg}(B)>1$. 
	If $m=0$, then $B=B'$, and so $B \in G_{j}$ and $\operatorname{deg}(B)>1$. Therefore $\lambda(B) \leq B_{j}^{*}$ by the inductive hypothesis. 
	If $m>0$, then $\lambda(B)=B_{j}^{*}$, and so $\lambda(B) \leq B_{j}^{*}$ as well. 
	So $\lambda(B) \leq B_{j}^{*}$ in either case. 
	Since $B_{j}^{*} < B_{j+1}^{*}$, we see that $\lambda(B) \leq B_{j+1}^{*}$, and the induction is complete.

	So we have completed the inductive construction of the $F_{j}$. 
	The construction shows that each $F_{j+1}$ is obtained from $F_{j}$ by adjoining an element $B_{j}^*$ of $\mathcal{B}$ which does not belong to $F_{j}$ and satisfies $B_{j}^{*} > B$ for all $B \in F_{j}$. 
	If we let $B_{j}=B_{j-1}^{*}$, we see that the $B_{j}$ are elements of $\mathcal{B}$ that satisfy $B_{1}<B_{2}<B_3<\dotsb$, and $F_j = \{ B_1, B_2, \dotsc, B_j \}$.
	Then \eqref{eq:21} becomes
	\begin{equation}
		S_{u}(t)=S_{u}^{j}(t) \cdot P_{u}^{j}(t)
	\end{equation}
	where
	\begin{equation}
		P_{u}^{j}(t)= \overleftarrow{\prod_{i \leq i \leq j}} \exp \left(C_{B_{i}}(u)(t) B_{i}\right).
	\end{equation}
	If we let $\delta_{j}=\operatorname{deg}\left(B_{j}^{*}\right)$, it is clear that $S_{u}^{j}(t)=1+Q_{u}^{j}(t)$, where $Q_{u}^{j}(t)$ contains no monomials of degree $<\delta_{j}$. Let $R_{u}^{0}(t)=P_{u}^{1}(t)$, and $R_{u}^{j}(t)=P_{u}^{j+1}(t)-P_{u}^{j}(t)$ for $j \geq 1$. Then $R_{u}^{j}=Q_{u}^{j} P_{u}^{j}-Q_{u}^{j+1} P_{u}^{j+1}$, so that $R_{u}^{j}(t)$ only contains monomials of degree $\geq \delta_{j}$. Since $\delta_{j} \rightarrow \infty$ as $j \rightarrow \infty$, the sum $\sum_{j=0}^{\infty} R_{u}^{j}(t)$ converges, and so the infinite product $\overleftarrow{\prod}_{1\leq i<\infty} \exp \left(C_{B_{i}}(u)(t) B_{i}\right)$ converges as well. Since
	\begin{equation}
		S_{u}(t)=P_{u}^{j}(t)+Q_{u}^{j}(t) P_{u}^{j}(t),
	\end{equation}
	we see that the coefficients of $S_{u}(t)$ and $P_{u}^{j}(t)$ agree up to degree $\delta_{j}-1$. Therefore
	\begin{equation}
		S_{u}(t)= \overleftarrow{\prod_{1 \leq i<\infty}} \exp \left(C_{B_{i}}(u)(t) B_{i}\right)
	\end{equation}
	Equivalently, we have
	\begin{equation} \label{eq:35}
		S_{u}(t)= \overleftarrow{\prod_{B \in F}} \exp \left(C_{B}(u)(t) B\right)
	\end{equation}
	where $F$ is the set whose elements are $B_{1}, B_{2}, \ldots$, ordered by the restriction of $\leq$ to $F$.	
	
	To complete our proof, we must show that $F=\mathcal{B}$. 
	This can be established in a number of ways. 
	We choose to use the Poincaré-Birkhoff-Witt theorem, according to which the elements of $A(\underline{X})$ that are of the form
	\begin{equation} \label{eq:36}
		B_{1}^{m_{1}} B_{2}^{m_2} \ldots B_{k}^{m_{k}}
	\end{equation}
	with $B_{1}, \ldots, B_{k}$ in $B$, and $B_{1}>B_{2}>\ldots>B_{k}$, form a basis of $A(\underline{X})$.
	Let $H$ denote the linear span of the elements of the form \eqref{eq:36} that are such that $B_{1}, \ldots, B_{k}$ are in $F$.
	If $F \neq \mathcal{B}$, then $H$ is a proper subspace of $A(\underline{X})$. We show that $H=A(\underline{X})$. Fix a multiindex $\sigma=\left(i_{1}, \ldots, i_{r}\right) \in \mathcal{I}(I)$. 
	Let $A_{r}(\underline{X})$ be the quotient algebra obtained by setting all monomials of degree $>r$ equal to zero, and let $\pi_{r}: A(\underline{X}) \rightarrow A_{r}(\underline{X})$ be the canonical homomorphism. 
	We can also regard $A_{r}(\underline{X})$ as a linear subspace of $A(\underline{X})$. 
	Let $H_{r}=H \cap A_{r}(X)$.
	It is clear from \eqref{eq:35} that $\pi_{r}\left(S_{u}(t)\right) \in H_{r}$ for every $u$, $t$. In particular, the product
	\begin{equation} \label{eq:37}
		\pi_{r}\left(\exp \left(t_{1} X_{i_{1}}\right) \ldots \exp \left(t_{r} X_{i_{r}}\right)\right)
	\end{equation}
	belongs to $H_{r}$ for every $t_{1}, \ldots, t_{r}$. If we differentiate \eqref{eq:37} with respect to $t_{1}, t_{2}, \ldots, t_{r}$ and then set $t_{1}=\ldots=t_{r}=0$, we find that $X_{\sigma} \in H_{r}$. 
	So $X_{\sigma} \in H$. 
	Since $\sigma$ was arbitrary, we conclude that $H=A(\underline{X})$. 
	So $F=\mathcal{B}$ and our proof is complete.
\end{proof}

We now turn to the question of the convergence of the product expansion. 

Formula \eqref{eq:19} makes it possible to prove bounds for the coefficients $C_{B}(u)(t)$. Assume that I is a finite set. For a $u \in U(I)$ with duration $T$, let $u=\left\{u_{i}(\cdot): i \in I\right\}$, and define $h_{u}(t)=\max \left\{\left|u_{i}(t)\right|: i \in I\right\}, H_{u}(t)=\int_{0}^{t} h_{u}(s) \dd s$. Then an easy induction gives the bounds
\begin{equation}
	\left|c_{B}(u)(t)\right| \leq H_{u}(t)^{(\operatorname{deg} B)-1}{h(t)}
\end{equation}
and then
\begin{equation} \label{eq:39}
	\left|C_{B}(u)(t)\right| \leq \frac{H_{u}(t)^{\operatorname{deg} B}}{\operatorname{deg} B} .
\end{equation}
These bounds are sufficient to prove that the product expansion \eqref{eq:20} converges in a slightly stronger sense. 
Suppose that $A=\left\{A_{i}: i \in I\right\}$ are square $n \times n$ matrices or, more generally, bounded operators on some Banach space. Let $M$ be an upper bound for the operator norms $\left\|A_{i}\right\|, i \in I$. For each bracket $B \in \Br$, let $B_{A}$ denote the operator obtained by substituting the $A_{i}$ for the $X_{i}$ in $B$. Then $\left\|B_{A}\right\| \leq 2^{(\operatorname{deg} B)-1} M^{\operatorname{deg} B}$ for all $B$. For a given $n$, there are at most $\nu^{n}$ elements of $\mathcal{B}$ of degree $n$. Hence the series
\begin{equation} \label{eq:40}
	\sum_{B} C_{B}(u)(t) B_{A}
\end{equation}
converges absolutely and uniformly on every interval $0 \leq t \leq \bar{t}$ such that
\begin{equation}
	\sum_{n=0}^{\infty} \frac{1}{n} \nu^{n} 2^{n-1} M^{n} (H_{u}(\bar{t}))^{n}<\infty .
\end{equation}
In particular, the series \eqref{eq:40} converges on $[0, \bar{t}]$ if $2 M \nu H_{u}(\bar{t})<1$. 
Since the $u_{i}(\cdot)$ are integrable, \eqref{eq:40} converges, for each $u$, on some interval $[0, \bar{t}]$, $\bar{t}>0$.

On the other hand, it is easy to see that, whenever \eqref{eq:40} converges absolutely, the infinite product $\prod_{B \in \mathcal{B}} \exp ( C_{B}(u)(t) B_{A})$ converges as well. 
So, for every choice of the $A_{i}$, and every $u$, the infinite product converges for sufficiently small times (or.\ for a fixed time interval $[0, \bar{t}]$, for sufficiently small controls $u$, the smallness being measured by the $L^1$ norm).

The presence of a factorial in \eqref{eq:19} might be regarded as an indication that \eqref{eq:39} is not the best possible bound for the $C_{B}(u)$, and that perhaps the $C_{B}(u)$ decrease faster than geometrically, and the series actually converges for all $u$ and all times. We show that this is not so by means of an example.

In order to construct our example, we take a set $I$ that has two elements, and let $X, Y$ denote the two indeterminates. 
We let $\mathcal{B}$ be an arbitrary P.\ Hall basis of $L(\underline{X})$. 
We take $u \in U(I)$ such that both functions $u_{i}(\cdot)$ are identically equal to one. 
Then the functions $c_{x}, c_{y}$ are equal to $1$.
An easy induction shows that, for each $B \in \Br$, the coefficient $c_{B}(t)$ is given by
\begin{equation}
	c_{B}(t)=\frac{t^{\operatorname{deg} B-1}}{A_{B}}
\end{equation}
where $A_{B}$ is a positive constant. 
The constants $A_{B}$ can be computed recursively by the formula
\begin{equation}
	A_B = A_{B_1}^m n_1^m m! A_{B_2},
\end{equation}
valid if $B = (\operatorname{ad} B_1)^m B_2$, $\lambda(B_2) \neq B_1$, and $n_i = \operatorname{deg} B_i$ for $i = 1,2$.

For $n \geq 1$, we let $\alpha_n$ denote the smallest of the $A_B$, for all $B \in \mathcal{B}$ such that $\operatorname{deg} B = n$.
We will prove that the upper bound
\begin{equation} \label{eq:44}
	\alpha_n \leq K \gamma^n
\end{equation}
holds for some $K>0$, $\gamma>0$. 
This implies that we can choose a sequence $B_1, B_2, B_{3}, \ldots$ of elements of $\mathcal{B}$, with deg $B_{n}=n$, such that the coefficients $c_{B_n}(t)$ satisfy $c_{B_{n}}(t) \geq \frac{\gamma^{-n} t^{n-1}}{K}$, so that $C_{B_{n}}(t) \geq \frac{1}{n K}\left(\frac{t}{\gamma}\right)^{n}$.
Therefore, the series $\sum_{n} C_{B_{n}}(t)$ does not converge if $t>\gamma$.

To prove the bound \eqref{eq:44} we begin by defining, for $k=2,3,4,\ldots$, a set $S_k$ of three elements of $\mathcal{B}$ of degree $2^k$.
We start by letting $S_2$ be the set whose elements are the three members of $\mathcal{B}$ that have degree $4$ (i.e.\ $[X,[X,[X,Y]]]$, $[Y,[X,[X,Y]]]$ and $[Y,[Y,[X,Y]]]$).
If $S_{k}$ has been defined, we let $S_{k+1}$ consist of the three brackets of the form $\left[B, B'\right]$ with $B \in S_k$, $B' \in S_k$, $B < B'$.
It is clear that $S_{k+1} \subseteq \mathcal{B}$. 
Next we let $\beta_{k}$ denote the maximum of the constants $A_B$ for $B \in S_{k}$.
If $B \in S_{k+1}$, we can write
\begin{equation}
	B = [B', B''], \quad B' \in S_k, B'' \in S_k.
\end{equation}
Since $\operatorname{deg} B' = \operatorname{deg} B''$, the left factor of $B''$ cannot be equal to $B'$.
Hence
\begin{equation}
	A_B = A_{B'} A_{B''} 2^k.
\end{equation}
Therefore,
\begin{equation}
	\beta_{k+1} \leq 2^{k} \beta_{k}^2.
\end{equation}
Then
\begin{equation}
	\log \beta_{k+1} \leq 2 \log \beta_{k}+k \log 2.
\end{equation}
Let $\theta_{k}=2^{-k} \log \beta_{k}$. 
Then
\begin{equation}
	\theta_{k+1} \leq \theta_{k}+2^{-k-1} k \log 2
\end{equation}
Therefore
\begin{equation}
	\theta_{k} \leq \theta_{2}+\sum_{j=2}^{k-1} 2^{-j-1} j \log 2.
\end{equation}
since the series $\sum_{j} 2^{-j-1} j \log 2$ converges, there is a constant $\eta$ such that $\theta_k \leq \eta$ for all $k$. 
So $\log \beta_{k} \leq \eta 2^{k}$, and then $\beta_{k} \leq \exp \left(\eta 2^{k}\right)$ for all $k$. 
So, if we let $\gamma=e^{n}$, we see that
\begin{equation}
	\beta_k \leq \gamma^{2^k} \quad \text{for } k = 2,3,\ldots.
\end{equation}
Since $\alpha_{2^k} \leq \beta_{k}$, we conclude that $\alpha_{n} \leq \gamma^{n}$ for all $n$ that are of the form $2^{k}$, $k=2,3,\ldots$. 
By taking a larger $\gamma$, if necessary, we can assume that the inequality also holds for $k=0,1$. 
So we have proved the desired bound, except for the fact that, so far, only values of $n$ of the form $2^{k}$ have been considered.

In order to extend the bound \eqref{eq:44} to arbitrary values of $n$, we pick an $n$ and express it as
\begin{equation}
	n=2^{k}+\varepsilon_{1} 2^{k-1}+\varepsilon_{2} 2^{k-2}+\ldots+\varepsilon_{k-1} 2 +\varepsilon_{k}
\end{equation}
where each $\varepsilon_{j}$ is either $0$ or $1$. 
We pick a $B \in S_{k}$ and modify it by suitable insertions to get an element of $\mathcal{B}$ that has degree $n$. 
Write $B=[B_{1}^{\#}, B_{2}]$, where $B_{1}^{\#} \in S_{k-1}$, $B_{2} \in S_{k-1}$ and $B_{1}^{\#} < B_{2}$.
If $\varepsilon_1=1$, let $B_{1}^{*}=[B_{1}^{\#},[B_{1}^{\#}, B_{2}]]$. 
Then
\begin{equation}
	A_{B_1^*} = 2 A_{B_1^\#}^{2} A_{B_{2}} 2^{k-1} \leq 2^{k} \beta_{k-1}^{3}
\end{equation}
and so
\begin{equation} \label{eq:54}
	A_{B_{1}^{*}} \leq 2^{k} \gamma^{3 \cdot 2^{k-1}}=2^{k} \gamma^{2^{k}+\varepsilon_1 2^{k-1}}.
\end{equation}
If $\varepsilon_{1}=0$, define $B_{1}^{*}=B$. Then it is clear that \eqref{eq:54} holds in this case as well.

We now have
\begin{equation}
	B_{1}^{*}=\left(\operatorname{ad} B_{1}^{\#}\right)^{\varepsilon_1+1}\left(B_{2}\right).
\end{equation}
Write $B_{2}=[B_{2}^{\#}, B_{3}]$, where $B_{2}^{\#}$ and $B_{3}$ are in $S_{k-2}$. Define
\begin{equation}
	B_{2}^{*}=\left(\operatorname{ad} B_{1}^{\#}\right)^{\varepsilon_{1}+1}\left(\operatorname{ad} B_{2}^{\#}\right)^{\varepsilon_{2}+1}\left(B_{3}\right).
\end{equation}
If $\varepsilon_{2}=1$, then
\begin{equation}
	A_{B_2^*} =2 A_{B_2^\#} 2^{k-2} A_{B_1^*},
\end{equation}
so that
\begin{equation}
	A_{B_2^*} \leq 2^{k-1} \beta_{k-2} 2^{k} \gamma^{2^{k}+\varepsilon_12^{k-1}} 
\end{equation}
and then
\begin{equation} \label{eq:59}
	A_{B_2^*} \leq 2^{k} 2^{k-1} \gamma^{2^{k}+\varepsilon_{1} 2^{k-1}+\varepsilon_{2} 2^{k-2}} .
\end{equation}
If $\varepsilon_{2}=0$ then \eqref{eq:59} holds as well.

This procedure can be continued, until we get an element $B_{k-2}^{*}$ of degree $2^{k}+\varepsilon_{1} 2^{k-1}+\ldots+4 \varepsilon_{k-2}$ which satisfies
\begin{equation}
	A_{B_{k-2}^{*}} \leq 2^{k} 2^{k-1} \cdots 2^{3} \gamma^{2^{k}+\varepsilon_1 2^{k-1}+\ldots+4 \varepsilon_{k-2}}
\end{equation}
and is of the form $(\operatorname{ad} B_1^\#)^{\varepsilon_{1}+1} \dotsb (\operatorname{ad} B_{k-2}^\#)^{\varepsilon_{k-2}+1} \left(B_{k-1}\right)$, where $B_{k-1} \in S_{2}$. 
Let $\nu=2 \varepsilon_{k-1}+\varepsilon_{k}$. 
Then $B_{k-1}=(\operatorname{ad} Z)^{\lambda}(\operatorname{ad} X)^{\mu}(Y)$, where either $\mu=1, \lambda=1$ and $Z=[X, Y]$, or $Z=Y$, $\mu \geq 1$, and $\mu+\lambda=3$. Define $\tilde{B}=(\operatorname{ad} Z)^{\lambda}(\operatorname{ad} X)^{\mu+\nu}(Y)$, and then let $(\operatorname{ad} B_1^\#)^{\varepsilon_{1}+1} \dotsb (\operatorname{ad} B_{k-2}^\#)^{\varepsilon_{k-2}+1} \left(\tilde{B}\right)$. 
Then $B^{*} \in \mathcal{B}$, $\operatorname{deg} B^{*}=n$, and
\begin{equation}
	A_{B^*}=\frac{(\mu+\nu) !}{\mu !} A_{B^{*}_{k-2}}.
\end{equation}
Since $1 \leq \mu \leq 3$ and $0 \leq \nu \leq 3$, we have $A_{B*} \leq 120 A_{B^*_{k-2}}$. 
Hence
\begin{equation}
	A_{B} * \leq 15 \times 2^{1+2+\ldots+k} \times \gamma^n
\end{equation}
so that
\begin{equation}
	A_{B^{*}} \leq 15 \times 2^{\frac{1}{2} k(k+1)} \times \gamma^{n}
\end{equation}
Since $2^{k+1}>n \geq 2^{k}$, we have
\begin{equation}
	A_{B^{*}} \leq 15 n^{\frac{1}{2}(k+1)} \gamma^{n}
\end{equation}
and then
\begin{equation}
	A_{B^*} \leq 15 n^{\frac{1}{2}+\sigma \log n} \gamma^{n},
\end{equation}
where $\sigma=\frac{1}{2 \log 2} \cdot$ Clearly, 
\begin{equation}
	15 n^{\frac{1}{2}+\sigma \log n} \leq K e^{\rho n}
\end{equation}
for some $K$, $\rho$ that do not depend on $n$. Hence, if we replace $\gamma$ by $e^{\rho} \gamma$, we get
\begin{equation*}
	A_{B^*} \leq K \gamma^{n}.
\end{equation*}
So $\alpha_{n} \leq K \gamma^{n}$, and \eqref{eq:44} is proved.


\color{black}

\begin{thebibliography}{1}
	\bibitem{1}
	Hall, M.,
	\newblock {\emph{Theory of groups}}.
	\newblock {The MacMillan Company}, 1959.
	
	\bibitem{2}
	Serre, J.P.,
	\newblock {\emph{Lie groups and Lie algebras}}.
	\newblock {W.A.\ Benjamin, Inc}, 1965.
	
	\bibitem{3}
	Viennot, G.,
	\newblock {\emph{Algèbres de Lie libres et monoides libres}}.
	\newblock {Springer Verlag}, 1978.
\end{thebibliography}


\end{document}