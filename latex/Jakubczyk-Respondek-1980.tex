\documentclass[leqno]{article}

\usepackage[width=13cm]{geometry}
\usepackage[utf8]{inputenc}
\usepackage{amsmath,amsfonts,amssymb,amsthm}
\usepackage{xcolor}
\usepackage[hidelinks,pdfusetitle]{hyperref}
\usepackage{enumerate}
\usepackage[capitalize]{cleveref}

\usepackage[version=4]{mhchem}
\usepackage{stmaryrd}
\usepackage{mathrsfs}
\usepackage{enumerate}

\theoremstyle{plain}
\newtheorem{lemma}{Lemma}
\newtheorem{theorem}{Theorem}
\newtheorem{remark}{Remark}
\newtheorem{corollary}{Corollary}

\numberwithin{equation}{section}

\title{On Linearization of Control Systems}

\author{Bronisław \textsc{Jakubczyk} and Witold \textsc{Respondek}\\
	\emph{Presented by C.\ Olech on December 7, 1979}}
\date{}

\newcommand{\ad}{\operatorname{ad}}
\newcommand{\dd}{\,\mathrm{d}}

\begin{document}
	
\noindent	
\textsc{Bulletin de l'Académie} \\
\textsc{Polonaise des Sciences} \\
Série des Sciences mathématiques \\
Vol.\ XXVIII, No.\ 9--10, 1980

\mbox{}\hfill \textsc{Systems, Control}

{\let\newpage\relax\maketitle}

\maketitle

\renewcommand*\abstractname{Summary.}
	
\begin{abstract}
	Necessary and sufficient conditions are given for the linearization of control system
	of the form	
	\begin{equation*}
		\dot{x}=f(x)+\sum u_{i} g_{i}(x)
	\end{equation*}
	under a class of transformations including changing of coordinates in the state and input spaces and feedback.
\end{abstract}
	
\section{Introduction}

 Consider a class of nonlinear control systems of the form

\begin{equation} \label{eq:1.1}
	\dot{x}=f(x)+\sum_{i=1}^{k} u_{i} g_{i}(x),
\end{equation}
where $x \in R^{n}$; $f, g_{1}, \ldots, g_{k}$ are $C^{\infty}$ vector fields on $R^{n}$ and $f(0)=0$. Let $G$ be a group of transformations of systems \eqref{eq:1.1} generated by
\begin{enumerate}[(i)]
	\item \label{i} change of coordinates in the state space $f, g_{i} \rightarrow \varphi_{*}(f), \varphi_{*}\left(g_{i}\right)$, where $\varphi: R^{n} \rightarrow R^{n}$ is a diffeomorphism preserving $0 \in R^{n}$.
	\item \label{ii} linear change of coordinates in the input space $R^{k}$, nonlinearly depending on $x$:
	\begin{equation*}
		g_{i} \rightarrow \sum_{j=1}^{k} h_{i j} g_{j}, \quad i=1, \ldots, k \text {, where } H(x)=\left(h_{i j}(x)\right)
	\end{equation*}
	is a $k \times k$ matrix of class $C^{\infty}$, nonsingular at $0 \in R^{n}$.
	\item \label{iii} feedback of the form: $f \rightarrow f+\sum_{i=1}^{k} \alpha_{i} g_{i}$, where $\alpha_{i}$ are $C^{\infty}$ functions, $\alpha_i: R^{n} \rightarrow R$ and $\alpha_{i}(0)=0$
\end{enumerate}

We consider a problem of linearizing system \eqref{eq:1.1} by means of transformations from the group $G$, i.e. transforming it via \eqref{i}-\eqref{iii} in a neighbourhood of zero to the form
\begin{equation} \label{eq:1.2}
	\dot{x}=A x+\sum_{i=1}^{k} u_{i} b_{i}
\end{equation}
where matrix $A$ and vector fields $b_{i}$, $i=1, \ldots, k$ are constant (in fact we are interested in controllable systems only). 
We give necessary and sufficient conditions for system \eqref{eq:1.1} to be locally linearizable. 

Our paper has been inspired by the paper of Brockett \cite{1}, where a criterion of linearization of system \eqref{eq:1.1} with scalar control is given. Our criterion is similar to that of \cite{1}, however Brockett considers a slightly different equivalence relation (the functions $h_{i j}(x)$ in \eqref{ii} are assumed to be constant).

The class of transformations $G$ is a natural modification of the class used by Brunovsky \cite{2} for the classification of linear controllable systems \eqref{eq:1.2}. 
Our linearization procedure leads to the Brunovsky canonical form and, as in the linear case the transformations can be taken linear, it gives also a proof of his theorem.

For the problem of linearization of systems \eqref{eq:1.1} under the transformations \eqref{i} the reader is referred to \cite{4}\footnote{In \cite{4} the linearization condition is stated with an error.} and \cite{5} (in the latter paper the case $f=0$ is considered). 
The problem of generic classification of systems \eqref{eq:1.1} with $f=0$ under the transformations \eqref{i} and \eqref{ii} was studied in \cite{3}.

\section{The main result}

Let $V\left(R^{n}\right)$ denote the family of all $C^{\infty}$ vector fields on $R^{n}$. For $f, g \in V\left(R^{n}\right)$ denote $\ad_{f} g=[f, g]$ and inductively $\ad_{f}^{i} g=[f, \ad_{f}^{i-1} g]$, $i=1,2,\dotsc$, where $[\cdot, \cdot]$ denotes the Lie bracket. 
To state the theorem we shall need the following conditions. Below $j$ denotes a nonnegative integer satisfying $0 \leqslant j \leqslant n-1$.

\begin{gather}
	\label{A1}\tag{A1} 
	\begin{split}
		& \text { For any } 0 \leqslant p \leqslant j \text { and } 1 \leqslant s, t \leqslant k \text { there are functions } \\
		& \qquad a_{i q} \in C^{\infty}\left(R^{n}\right) \text { such that }\left[\ad_{f}^{p} g_{s}, \ad_{f}^{j} g_{t}\right]=\sum_{\substack{0 \leqslant q \leqslant j \\
				1 \leqslant i \leqslant k}} \alpha_{i q} \ad_{f}^{q} g_{i}
	\end{split}
	\\
	\label{A2}\tag{A2} 
	\operatorname{dim} \operatorname{span}\left\{\ad_{f}^{q} g_{i}(x) \mid 0 \leqslant q \leqslant j, 1 \leqslant i \leqslant k\right\}=r_{j}(x)=\text {const.}
	\\
	\operatorname{dim} \operatorname{span}\left\{\ad_{f}^{q} g_{i}(x) \mid 0 \leqslant q \leqslant n-1,1 \leqslant i \leqslant k\right\}=r_{n-1}(x)=n.
	\label{A3}\tag{A3}
\end{gather}

Those conditions we express now in an invariant form. For any subset $A \subset V\left(R^{n}\right)$ we denote by $\langle A\rangle$ a submodule of $V\left(R^{n}\right)$ generated by $A$ over the ring of smooth functions. Put $\mathscr{G}=\left\langle g_{1}, \ldots, g_{k}\right\rangle$, $\mathscr{G}_{f}=f+\mathscr{G}=\{f+g \mid g \in \mathscr{G}\}$ and by induction

\begin{equation*}
	\mathscr{M}^{0}=\mathscr{G}, \quad 
	\mathscr{M}^{j}=\left\langle\left[\mathscr{G}_{f}, \mathscr{M}^{j-1}\right], \mathscr{M}^{j-1}\right\rangle,
\end{equation*}
where $[A, B]=\{[a, b] \mid a \in A, b \in B\}$ for any $A, B \subset V\left(R^{n}\right)$. Let $\mathscr{M}^{j}(x)=\{g(x) \mid g \in \mathscr{M}^{j}\} \subset T_{x} R^{n}$ and denote $m_{j}(x)=\operatorname{dim} \mathscr{M}^{j}(x)$. 
It is easy to see that subsets $\mathscr{G}$, $\mathscr{G}_{f} \subset V\left(R^{n}\right)$ are invariant under the transformations \eqref{ii}, \eqref{iii}. 
Thus, since the Lie bracket is invariant under \eqref{i}, the following conditions are invariant under the group $G$ ($j$ denotes a nonnegative integer satysfying $0 \leqslant j \leqslant n-1$)

\begin{gather}
	\label{B1} \tag{B1}
	\begin{split}
		\mathscr{M}^{j} & \text{ are closed with respect to Lie bracket i.e.}  \\
		& g', g'' \in \mathscr{M}^{j} \Rightarrow\left[g', g''\right] \in \mathscr{M}^{j},
	\end{split}
	\\
	\label{B2} \tag{B2}
	m_{j}(x)=\mathrm{const},
	\\
	\label{B3} \tag{B3}
	m_{n-1}(x)=n.
\end{gather}


We will use the following notations $p_{0}(x)=r_{0}(x)$ and $p_{j}(x)=r_{j}(x)-r_{j-1}(x)$ for $j = 1, \dotsc, n-1$. It can be easily seen that $p_{0}(x) \geqslant p_{j}(x) \geqslant \ldots \geqslant p_{n-1}(x) \geqslant 0$.

To introduce the Brunovsky canonical form let us denote by $N$ the smallest number such that $r_{N}(x)=n$. 
It exists if \eqref{A3} holds. 
It will be proved that condition \eqref{B1} implies $r_{j}(x)=m_{j}(x)$ and in this case $\left\{p_{j}(x)\right\}$ and the number $N$ can also be defined using $\{m_j(x)\}$ instead of $\{r_j(x)\}$.
It is obvious that for $j =N, N+1, \dotsc, n-1$ we have $r_j(x) = n$.

Let $r_j(x)$ and $p_j(x)$ be constant (it is the case when \eqref{A2} is satisfied).
We will omit in notations the dependence on $x$ and we will rite $r_j$ and $p_j$.
Let $\left(x_{1}, x_{2}, \ldots, x_{n}\right)=x$ denote the coordinates of $R^{n}$. 
We shall denote $x = \left(x^{0}, x^{1}, \ldots, x^{N}\right)$ where $x^0$ consists of the first $p_0$ coordinates of $x$, $x^{1}$ consists of the next $p_1$ coordinates, ..., $x^{N}$ consists of the last $p_{N}$ coordinates of $x$. 
In any group $x^j$ denote by $\tilde{x}^j$ the first $p_{j+1}$ coordinates. 
System \eqref{eq:1.1} of the form

\begin{equation} \label{eq:2.1}
	\begin{split}
		& g_{1}=(1,0, \ldots, 0), \quad 
		g_{2}=(0,1,0, \ldots, 0), \quad 
		g_{r_{0}}=(\underbrace{0, \ldots, 0}_{(r_{0}-1)\text { times }},1,0, \ldots, 0) \\
		& g_{i}=(0,0, \ldots, 0) \quad i=r_{0}+1, \ldots, k \text {, } \\
		& f=(\underbrace{0, \ldots, 0}_{r_{0} \text { times }}, \tilde{x}^{0}, \tilde{x}^{1}, \ldots, \tilde{x}^{N-1})
	\end{split}
\end{equation}
will be called system in the Brunovsky canonical form.

\begin{theorem}
	\label{thm:1}
	The following conditions are equivalent, locally around $0 \in R^{n}$:
	\begin{enumerate}[(a)]
		\item \label{a} system \eqref{eq:1.1} is $G$-linearizable to a controllable system \eqref{eq:1.2},
		\item \label{b} system \eqref{eq:1.1} is $G$-equivalent to a system in the Brunovsky canonical form,
		\item \label{c} conditions \eqref{A1}-\eqref{A3} are satisfied,
		\item \label{d} conditions \eqref{B1}-\eqref{B3} are satisfied.
	\end{enumerate}
\end{theorem}

The Theorem can also be formulated in a more abstract way. Namely

\begin{corollary}
	Let $\mathscr{G}$ be a finitely generated submodule of $V\left(R^{n}\right)$ and $\mathscr{G}_{f}=f+\mathscr{G}$, where $f \in V\left(R^{n}\right)$, $f(0)=0$.
	Then there exists a system of coordinates in a neighbourhood of 0 such that $\mathscr{G}$ and $\mathscr{G}_{f}$ can be expresed by $\left\langle g_{1}', \ldots, g_{k}'\right\rangle$ and $f'+\mathscr{G}'$, respectively with $f'$ and $g_{i}'$ of the form \eqref{eq:2.1} if and only if the conditions \eqref{B1}-\eqref{B3} are satisfied in a neighbourhood of~0.
\end{corollary}
	
\begin{remark}
	 Conditions \eqref{A1}, \eqref{A3} are straightforward modifications of the conditions of Brockett \cite{1}. 
	 In \cite{1} the sum on the right hand side of \eqref{A1} is taken only for $g<j$. 
	 This is due to the fact that Brockett assumed the functions $h_{ij}(x)$ in \eqref{ii} to be constant. 
	 In the scalar control case (like in $\cite{1}$) the condition \eqref{A2} follows from \eqref{A3}.
\end{remark}

\begin{remark}
	The Theorem also holds for the class of systems \eqref{eq:1.1} not satisfying $f(0)=0$. 
	In this case we have to use a larger class of transformations admitting in \eqref{iii} $\alpha_{i}$ not equal zero at zero. 
	The field $f$ in \eqref{eq:2.1} is then, in general, a sum  of constant vector field and that of \eqref{eq:2.1}.
\end{remark}

In the proof of \cref{thm:1} we shall use the following modification of the Frobenius theorem.

\begin{lemma}
	\label{lemma:1}
	Let $D_{0} \subset D_{1} \subset \ldots \subset D_{N}$ denote a sequence of involutive $C^{\infty}$ distributions
	on a manifold $M$ ($\operatorname{dim} M=n$) having constant dimensions $\mu_{0} \leqslant \mu_{1} \leqslant \ldots \leqslant \mu_{N}$, respectively. 
	Then, around any point $x_{0} \in M$, there exists a coordinate system $\left(x_{1}, \ldots, x_{n}\right)$ such that the integral manifolds of $D_{i}$ around $x_{0}$ are of the form
	\begin{equation*}
		x_i = C_i, \quad i = \mu_j+1, \dotsc, n.
		\quad C_i \text{ constant}.
	\end{equation*}
\end{lemma}

\begin{proof}
	Let $f_{1}, \ldots, f_{\mu_{0}}$ be vector fields which generate the distribution $D_{0}$ around $x_{0}$, $f_{1}, \ldots, f_{\mu_{1}}$ generate $D_{1}$, ..., $f_{1}, \ldots, f_{\mu_{N}}$ generate the distribution $D_{N}$ around $x_{0}$.
	Choose vector fields $f_{\mu_{N}+1}, \ldots, f_{n}$ in such a way that $f_{1}, \ldots, f_{n}$ generate $T_{x_{0}} M$.
	
	Consider the map $T$
	\begin{equation*}
		\left(t_{1}, \ldots, t_{n}\right) \stackrel{T}{\longrightarrow} e^{t_{1} f_{1}} \circ \ldots \circ e^{t_{n} f_{n}}\left(x_{0}\right) \in M,
	\end{equation*}
	where $e^{t_{i} f_{i}}$ denotes the (local) flow generated by $f_{i}$. 
	Let $V$ denote a cube neighbourhood of $0 \in R^{n}$ such that $T: V \to U=T(V)$ is a diffeomorphism.
	Then $\left(U, T^{-1}\right)$ is a desired coordinate system.
	
	According to the Frobenius theorem $D_{j}$ defines in $U$ a foliation $\mathscr{A}$ with $\mu_j$ dimensional leaves (maximal integral manifolds of $D_{j}$). 
	These leaves are exactly the leaves of the foliation $\mathscr{B}$ constructed as follows. 
	For any point $y \in U$ of the form $y=e^{t_{\mu_{j+1}}f_{\mu_{j+1}} } \circ \ldots \circ e^{t_n f n}\left(x_{0}\right)$ we define a submanifold $N_{Y}$ which passes through $y$ by
	
	\begin{equation*}
		N=\left\{p \in U \mid p=e^{t_{1} f_{1}} \circ \ldots \circ e^{t_{\mu_{j}} f_{\mu_{j}}}(y)\right\}
	\end{equation*}
	(it is a $\mu_{j}$ dimensional submanifold by the regularity of $T$).
	
	To prove the coincidence of $\mathscr{A}$ and $\mathscr{B}$ note that integral manifolds of $D_{j}$ are equal to orbits of the family of vector fields generating $D_{j}$ (Sussmann \cite{6}), so $N_{Y}$ is contained in the maximal integral manifold of $D_{j}$ passing through $y$. 
	Moreover, $N_{\mathrm{Y}}$ is closed (trivial) and open (by the equality of dimensions) subset of the maximal integral manifold of $D_{j}$ passing through $y$. 
	Therefore, they are equal.
	
	Since $T$ is bijective it follows that $Z_{1}, Z_{2} \in U$ belong to the same leaf of the foliation $\mathscr{B}$ if and only if $t_{i}\left(Z_{1}\right)=t_{i}\left(Z_{2}\right)$ $i=\mu_{j}+1, \ldots, n$. This and the fact that $\mathscr{A}$ and $\mathscr{B}$ coincide concludes the proof that $t_{1}, \ldots, t_{n}$ are the desired coordinates.
\end{proof}

\section{Proof of \texorpdfstring{\cref{thm:1}}{Theorem 1}}

The implication \eqref{b} $\Rightarrow$ \eqref{a} is trivial. 
To prove \eqref{a} $\Rightarrow$ \eqref{d} let us notice that condition \eqref{d} is $G$-invariant and for the linear system \eqref{eq:1.2} we have $\mathscr{G}=\left\langle b_{1}, \ldots, b_{k}\right\rangle$, $\mathscr{M}^{j}=\left\langle A^{q} b_{i} \mid 0 \leqslant q \leqslant j, 1 \leqslant i \leqslant k\right\rangle$, i.e.\ for this system condition \eqref{d} is satisfied.

\bigskip

\eqref{d} $\Rightarrow$ \eqref{c}. 
We shall prove using an induction argument with respect to $j$ that \eqref{B1}, $j=0, \ldots, n-1$ imply the equalities
\begin{equation} \label{eq:3.1}
	\mathscr{M}^{j}=\left\langle \ad_{f}^{q} g_{i} \mid 0 \leqslant q \leqslant j, \quad 1 \leqslant i \leqslant k\right\rangle, \quad j=0, \ldots, n-1
\end{equation}
For $j=0$ this is trivial. Assume that this is true for $j-1$.
The inclusion ``$\supset$'' follows from the definition of $\mathscr{M}^{j}$. 
To prove the converse one, note that from \eqref{B1} we have $\left[\mathscr{G}, \mathscr{M}^{j-1}\right] \subset \mathscr{M}^{j-1}$. Thus $\left[\mathscr{G}_{f}, \mathscr{M}^{j-1}\right]=\left[f+\mathscr{G}, \mathscr{M}^{j-1}\right] \subset\left[f, \mathscr{M}^{j-1}\right]+\left[\mathscr{G}, \mathscr{M}^{j-1}\right] \subset \left[f, \mathscr{M}^{j-1}\right]+\mathscr{M}^{j-1}$. Therefore
\begin{equation*}
	\mathscr{M}^{j}=\left\langle\left[\mathscr{G}_{f}, \mathscr{M}^{j-1}\right], \mathscr{M}^{j-1}\right\rangle \subset\left\langle\left[f, \mathscr{M}^{j-1}\right], \mathscr{M}^{j-1}\right\rangle .
\end{equation*}
This and the induction assumption on the form of $\mathscr{M}^{j-1}$ give the desired inclusion.

The conditions \eqref{B1}-\eqref{B3} and equality \eqref{eq:3.1} imply easily the conditions \eqref{A1}-\eqref{A3}.

\bigskip

\eqref{c} $\Rightarrow$ \eqref{b}. 
We denote $f=\left(f^{0}, f^{1}, \ldots, f^{N}\right)$, where $f^{0}$ consists of the first $p_{0}$ coordinates of $f=\left(f_{1}, \ldots, f_{n}\right)$, $f^{1}$ consists of the next $p_{1}$ coordinates, ..., $f^{N}$ consists of the last $p_N$ coordinates.
We shall also use the notations from \eqref{eq:2.1}.

The distributions $D_{j}$ generated by $R_{j}=\left\{\ad_{f}^{q} g_{i} \mid 0 \leqslant q \leqslant j, 1 \leqslant i \leqslant k \right\}$ satisfy the assumptions of \cref{lemma:1}.
Let us choose the coordinates around $0 \in R^{n}$ in such a way that the integral manifolds of $D_{j}$, $j=0, \ldots, N$ are given by $x_{i}=c_{i}$, $i=r_{j}+1, \ldots, n$. 
We assume that $f$ and $g_{i}'$s in \eqref{eq:1.1} are expressed in this coordinate system. 
All our future changes of coordinates will preserve the above integral manifolds. 
The form of the integral manifolds of $D_{j}$ implies that the vector fields in $R_j$ have zero components along the last $n-r_{j}$ coordinates. 
Using this fact and $\operatorname{dim} \operatorname{span} R_{j}(x)=r_{j}$ we shall prove that the coordinates of $f^{j}$ do not depend on the variables $x^{0}, \ldots, x^{j-2}$ ($j \geqslant 2$) and $\operatorname{rank}\frac{\partial f^{j}}{\partial x^{j-1}}(x)=p_{j}$. 
Note first that for $g \in R_{j-1}$ we have that $g$ and so $D g \cdot f$ are equal to zero along the last $n-r_{j-1}$ coordinates. 
Thus, along these coordinates $[f, g]$ is equal to $-D f \cdot g$. 
In particular if $g' \in R_{j-2}$ then we have $D f^{j} g=0$ by the fact that $\left[f, g'\right] \in R_{j-1}$. 
This gives that $f^{j}$ does not depend on $x^{0}, \ldots, x^{j-2}$. 
The equality $\frac{\partial f^{j}}{\partial x^{j-1}}(x)=p_{j}$ is a consequence of the fact that there are $p_{j}$ independent vectors among $[f, g]$, $g \in R_{j-1}$.

Now we shall transform the vector field $f=\left(f^{0}, \ldots, f^{N}\right)$ to the canonical form \eqref{eq:2.1}.
We shall use the same notations to express it in an old coordinate system and in a new one. 
In the first step we introduce the new coordinates $y^{N-1}=\left(f^{N}, \tilde{\tilde{x}}^{N-1}\right)$, $y^j=x^{j}$ if $j \neq N-1$, where $\tilde{\tilde{x}}^{N-1}$ denotes $p_{N-1}-p_{N}$ coordinates of $x^{N-1}$ chosen in such a way that $\operatorname{rank} \frac{\partial y^{N-1}}{\partial x^{N-1}}(0)=p_{N-1}$ (this is possible since $\operatorname{rank} \frac{\partial f^{N}}{\partial x^{N-1}}(0)=p_{N}$). 
We obtain $f$ in the form $\left(f^{0}, \ldots, f^{N-1}, \tilde{x}^{N-1}\right)$, where we write $\tilde{x}^{N-1}$ instead of $\tilde{y}^{N-1}$ to use consequently notation $x$ for coordinates.
In the second step we introduce the new coordinates $y^{N-2}=\left(f^{N-1}, \tilde{\tilde{y}}^{N-2}\right)$ and get $f=\left(f^{0}, \ldots, f^{N-2}, \tilde{x}^{N-2}, \tilde{x}^{N-1}\right)$. 
After $N-1$ steps we obtain $f=\left(f^{0}, \tilde{x}^{0}, \ldots, \tilde{x}^{N-1}\right)$.

By the form of the distribution $D_{0}$ we can transform the vector fields $g_{i}$, $i=1, \ldots, k$ to the canonical form $g_{i}=(\underbrace{0, \ldots, 0}_{(i-1) \text { times }}, 1,0, \ldots, 0)$ for $f=\left(0, \tilde{x}^{0}, \ldots, \tilde{x}^{N-1}\right)$. 
The proof is complete.

\bigskip

\textbf{Added in proof.} After this paper had been submitted, R.\ W.\ Brockett informed us that he had obtained an analogous result.

\bigskip

{\footnotesize
\textsc{Institute of Mathematics, Polish Academy of Sciences, \'Sniadeckich 8, 00-950 Warsaw (Instytut Matematyczny, Pan)}

\textsc{Institute of Mathematics, Technical University, Pl.\ Jedno\'sci Robotniczej 1, 00-661 Warsaw (Instytut Matematyczny, Politechnika Warszawska)}
}

\begin{thebibliography}{1}
	
	\bibitem{1}
	R.\ W.\ Brockett,
	\newblock \emph{Feedback invariants for nonlinear systems},
	\newblock in Proc.\ IFAC Congress, Helsinki, 1978
		
	\bibitem{2} P.\ Brunovsky,
	\newblock \emph{A classification of linear controllable systems},
	\newblock Kybernetica, 173-180, 1970
		
	\bibitem{3} B.\ Jakubczyk, F.\ Przytycki,
	\newblock \emph{Singularities of $k$-tuples of vector fields},
	\newblock Preprint No.\ 158, Institute of Mathematics, Polish Academy of Sciences, Warsaw, 1978
		
	\bibitem{4} A.\ J.\ Krener,
	\newblock \emph{On the equivalence of control systems and linearization of nonlinear systems}
	\newblock SIAM J.\ Contr.\ and Optim., 11, 1973
		
	\bibitem{5} J.\ L.\ Sedwick, D.\ L.\ Elliott,
	\newblock \emph{Linearization of analytic vector fields in the transitive case},
	\newblock J.\ Diff.\ Equat., 25, 1977
		
	\bibitem{6} H.\ J.\ Sussmann,
	\newblock \emph{Orbits of families of vector fields and integrability of distributions},
	\newblock Trans.\ Am.\ Math.\ Soc., 180, 171-188, 1973

\end{thebibliography}


\end{document}